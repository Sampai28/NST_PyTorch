{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NST_PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehkOEWiTu6w3"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms #convert image to tensor\n",
        "import torchvision.models as models  #to use a pre-trained model\n",
        "from torchvision.utils import save_image #storing the generated image\n",
        "\n",
        "from PIL import Image #load the image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSY4s67fzFMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a10499-3494-4f20-f36b-62c667279875"
      },
      "source": [
        "model = models.vgg19(pretrained=True).features\n",
        "print(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (26): ReLU(inplace=True)\n",
            "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (31): ReLU(inplace=True)\n",
            "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (33): ReLU(inplace=True)\n",
            "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (35): ReLU(inplace=True)\n",
            "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87zRKcAPzphq"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG, self).__init__()\n",
        "    self.chosen_features = ['0', '5', '10', '19', '28']\n",
        "    self.model = models.vgg19(pretrained=True).features[:29]\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = []\n",
        "    for layer_num, layer in enumerate(self.model):\n",
        "      x = layer(x)\n",
        "      if str(layer_num) in self.chosen_features:\n",
        "        features.append(x)\n",
        "    return features"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tl8JC-JaSD6"
      },
      "source": [
        "def load_img(img_name):\n",
        "  img = Image.open(img_name)\n",
        "  img = loader(img).unsqueeze(0) #we need to add additional dimension\n",
        "  return img.to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjkk4E7eawuU",
        "outputId": "c87154fe-9e59-49f4-aea5-2da5a255b6c3"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "device"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjnZ0gZgnP9M"
      },
      "source": [
        "img_size = 200"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSMIEu49nWM3"
      },
      "source": [
        "loader = transforms.Compose(\n",
        "    [\n",
        "      transforms.Resize((img_size, img_size)),\n",
        "      transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLLkCxfoDxq"
      },
      "source": [
        "original_img = load_img('naruto.jpg')\n",
        "style_img = load_img('style.jpg')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXK5aKRjxlU8"
      },
      "source": [
        "model = VGG().to(device).eval() #freeze weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibI7imD9szFz"
      },
      "source": [
        "generated = original_img.clone().requires_grad_(True) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNW4_1awv-k4"
      },
      "source": [
        "#hyperparameters\n",
        "total_steps = 6000\n",
        "learning_rate = 0.001\n",
        "alpha = 1\n",
        "beta = 0.01\n",
        "optimizer = optim.Adam([generated], lr= learning_rate) "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yMOiD_pwZcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8219791b-02cd-4123-a98f-2e0dff21912d"
      },
      "source": [
        "for step in range(total_steps):\n",
        "  generated_features = model(generated)\n",
        "  original_features = model(original_img)\n",
        "  style_features = model(style_img)\n",
        "\n",
        "  style_loss = original_loss = 0\n",
        "\n",
        "  for gen_feature, original_feature, style_feature in zip(generated_features, original_features, style_features):\n",
        "    batch_size, channel, height, width = gen_feature.shape\n",
        "    original_loss +=torch.mean((gen_feature - original_feature)**2)\n",
        "\n",
        "    #compute gram matrix\n",
        "    G = gen_feature.view(channel, height*width).mm(gen_feature.view(channel, height*width).t())\n",
        "    S = style_feature.view(channel, height*width).mm(style_feature.view(channel, height*width).t())\n",
        "\n",
        "    style_loss+= torch.mean((G-S)**2)\n",
        "\n",
        "  total_loss = alpha*original_loss + beta*style_loss\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "  if step%200 == 0:\n",
        "    print(total_loss)\n",
        "    save_image(generated, \"gen.jpg\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(119825.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(28667.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8485.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4171.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2627.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2100.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1804.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1569.4468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1380.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1230.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1107.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1010.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(933.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(872.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(821.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(778.1966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(739.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(702.7082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(669.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(639.5064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(610.5347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(583.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(559.8788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(538.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(519.6727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(502.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(486.4581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(472.3233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(458.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(442.9379, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGWLzBgxHRQ"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}